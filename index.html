<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Dylan Lim</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 650px;
            margin: 0 auto;
            padding: 60px 20px;
            background-color: #fff;
        }

        header {
            margin-bottom: 60px;
        }

        h1 {
            font-size: 28px;
            font-weight: 600;
            margin-bottom: 10px;
            color: #111;
        }

        .subtitle {
            font-size: 16px;
            color: #666;
            margin-bottom: 15px;
        }

        .contact {
            font-size: 14px;
            color: #666;
        }

        .contact a {
            color: #0066cc;
            text-decoration: none;
            margin-right: 15px;
        }

        .contact a:hover {
            text-decoration: underline;
        }

        section {
            margin-bottom: 45px;
        }

        h2 {
            font-size: 18px;
            font-weight: 600;
            margin-bottom: 20px;
            color: #111;
            text-transform: uppercase;
            letter-spacing: 0.5px;
        }

        .experience-item, .project-item, .education-item {
            margin-bottom: 25px;
        }

        .experience-header, .project-header {
            display: flex;
            justify-content: space-between;
            align-items: baseline;
            margin-bottom: 5px;
        }

        .position {
            font-weight: 500;
            color: #111;
        }

        .company {
            color: #666;
            font-weight: normal;
        }

        .date {
            font-size: 14px;
            color: #999;
            white-space: nowrap;
        }

        .description {
            color: #555;
            margin-top: 5px;
            font-size: 15px;
        }

        .description ul {
            margin-left: 20px;
            margin-top: 8px;
        }

        .description li {
            margin-bottom: 5px;
        }

        .description a {
            color: #0066cc;
            text-decoration: none;
        }

        .description a:hover {
            text-decoration: underline;
        }

        .intro {
            font-size: 16px;
            color: #444;
            line-height: 1.7;
            margin-bottom: 45px;
        }

        .intro a {
            color: #0066cc;
            text-decoration: none;
        }

        .intro a:hover {
            text-decoration: underline;
        }

        .highlight {
            font-weight: 500;
            color: #111;
        }

        .awards {
            color: #555;
            font-size: 15px;
            line-height: 1.8;
        }

        .project-link {
            color: #0066cc;
            text-decoration: none;
        }

        .project-link:hover {
            text-decoration: underline;
        }

        @media (max-width: 600px) {
            .experience-header, .project-header {
                flex-direction: column;
            }
            .date {
                margin-top: 5px;
            }
        }
    </style>
</head>
<body>
    <header>
        <h1>Dylan Lim</h1>
        <div class="subtitle">CS @ Stanford · ML Systems · Performance Engineering</div>
        <div class="contact">
            <a href="mailto:dylanlim@stanford.edu">email</a>
            <a href="https://linkedin.com/in/dylanllim" target="_blank">linkedin</a>
            <a href="https://x.com/dylan__lim" target="_blank">x/twitter</a>
        </div>
    </header>

    <section class="intro">
        Hi! I'm a graduate student at Stanford working on making fast and efficient machine learning systems 
        <br><br>
        I currently work at 
        <a href="https://hazyresearch.stanford.edu/">Hazy Research</a>, where I build systems that push the boundaries 
        of GPU performance. My work spans from kernel to distributed training optimizations.
    </section>

    <section>
        <h2>Research</h2>
        
        <div class="experience-item">
            <div class="experience-header">
                <div>
                    <span class="position">Hazy Research Lab</span>
                    <span class="company">· Stanford</span>
                </div>
                <span class="date">current</span>
            </div>
            <div class="description">
                Building <a href="https://hazyresearch.stanford.edu/blog/2024-11-07-tk-intro">ThunderKittens</a> and 
                <a href="https://hazyresearch.stanford.edu/blog/2024-12-09-megakernels">Megakernels</a> — new approaches to GPU kernel design. 
                Our work achieves state-of-the-art performance for LLM inference through aggressive kernel fusion and novel GPU programming patterns. 
                Also developing <a href="https://github.com/HazyResearch/ThunderKittens">ThunderGang</a> for efficient multi-GPU communication with NVLink.
            </div>
        </div>

        <div class="experience-item">
            <div class="experience-header">
                <div>
                    <span class="position">FlexFlow Project</span>
                    <span class="company">· Stanford</span>
                </div>
                <span class="date">2024-2025</span>
            </div>
            <div class="description">
                Working on <a href="https://github.com/flexflow/FlexFlow">FlexFlow</a>, a distributed deep learning compiler that automatically discovers 
                optimal parallelization strategies. Recipient of VPUE Research Grant and CURIS Fellowship.
            </div>
        </div>

        <div class="experience-item">
            <div class="experience-header">
                <div>
                    <span class="position">Autonomous Agents Lab</span>
                    <span class="company">· Stanford & Google Research</span>
                </div>
                <span class="date">2023-2024</span>
            </div>
            <div class="description">
                Research on open-vocabulary 3D scene generation and layout understanding. Paper accepted to CVPR 2025.
            </div>
        </div>
    </section>

    <section>
        <h2>Industry</h2>
        
        <div class="experience-item">
            <div class="experience-header">
                <div>
                    <span class="position">Quantitative Development</span>
                    <span class="company">· Jump Trading</span>
                </div>
                <span class="date">Summer 2025</span>
            </div>
            <div class="description">
                Designed and implemented a distributed GPU compute orchestration system. Achieved order-of-magnitude performance improvements 
                through RDMA networking, dynamic kernel compilation, and novel scheduling algorithms. Also placed well in the intern poker tournament.
            </div>
        </div>

        <div class="experience-item">
            <div class="experience-header">
                <div>
                    <span class="position">HPC Engineering</span>
                    <span class="company">· Valuenex</span>
                </div>
                <span class="date">Spring 2024</span>
            </div>
            <div class="description">
                Optimized graph visualization algorithms achieving ~10× speedup through parallelization and cache-aware data structures.
            </div>
        </div>

        <div class="experience-item">
            <div class="experience-header">
                <div>
                    <span class="position">Software Engineering</span>
                    <span class="company">· Candid</span>
                </div>
                <span class="date">2023-2024</span>
            </div>
            <div class="description">
                Built high-performance backend systems including RAG pipelines, real-time transcription, and video processing infrastructure.
            </div>
        </div>
    </section>

    <section>
        <h2>Projects</h2>
        
        <div class="project-item">
            <div class="project-header">
                <span class="position"><a href="https://hazyresearch.stanford.edu/blog/2024-12-09-megakernels" class="project-link">Megakernels</a></span>
            </div>
            <div class="description">
                On-GPU interpreter that fuses hundreds of operations into single kernels. Achieves record-breaking inference latency 
                for Llama models with up to 3.5× speedups over existing systems.
            </div>
        </div>

        <div class="project-item">
            <div class="project-header">
                <span class="position"><a href="https://github.com/HazyResearch/ThunderKittens" class="project-link">ThunderGang</a></span>
            </div>
            <div class="description">
                PTX-level extension for device-initiated NVLink collectives, enabling significant speedups over NCCL for multi-GPU workloads.
            </div>
        </div>

        <div class="project-item">
            <div class="project-header">
                <span class="position">FlexGraph</span>
            </div>
            <div class="description">
                Framework for generating diverse ML model architectures to evaluate and benchmark ML compilers.
            </div>
        </div>

        <div class="project-item">
            <div class="project-header">
                <span class="position">Shard</span>
            </div>
            <div class="description">
                Custom distributed training system with pipeline parallelism for heterogeneous GPU clusters.
            </div>
        </div>
    </section>

    <section>
        <h2>Writing</h2>
        <div class="description">
            <a href="https://hazyresearch.stanford.edu/blog/2024-12-09-megakernels">Look Ma, No Bubbles! Designing Low-Latency Megakernels</a> - 
            Technical deep dive into eliminating kernel launch overhead for LLM inference
            <br><br>
            Multi-GPU Kernel Design and Communication Patterns (coming soon) - 
            Practical guide to building efficient distributed GPU kernels
        </div>
    </section>

    <section>
        <h2>Recognition</h2>
        <div class="awards">
            Stanford Competitive Programming Team · TreeHacks Best Startup Award · 
            Stanford Data Science (Former Director) · ACM Neural Network Competition Winner · 
            Alex Tung Memorial Fellow · Pear Garage Fellow · VPUE Research Grant · CURIS Scholar
        </div>
    </section>
</body>
</html>
